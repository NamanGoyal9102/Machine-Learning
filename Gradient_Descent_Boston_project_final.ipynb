{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "53ce0444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "e1d2c315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 14)\n",
      "[[-0.40784991 -0.48772236 -1.2660231  ...  0.41057102 -1.09799011\n",
      "  37.9       ]\n",
      " [-0.40737368 -0.48772236  0.24705682 ...  0.29116915 -0.52047412\n",
      "  21.4       ]\n",
      " [ 0.1251786  -0.48772236  1.01599907 ... -3.79579542  0.89107588\n",
      "  12.7       ]\n",
      " ...\n",
      " [-0.40831101 -0.48772236  0.24705682 ...  0.33206621 -0.33404299\n",
      "  20.8       ]\n",
      " [-0.41061997 -0.48772236 -1.15221381 ...  0.203235   -0.74475218\n",
      "  22.6       ]\n",
      " [ 0.34290895 -0.48772236  1.01599907 ...  0.38787479 -1.35871335\n",
      "  50.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.40098068, -0.49042688, -1.28149216, ..., -0.32264241,\n",
       "         0.42027996, -1.10095452],\n",
       "       [-0.40053396, -0.49042688,  0.20753471, ...,  0.09391068,\n",
       "         0.30257958, -0.53143278],\n",
       "       [ 0.09900799, -0.49042688,  0.96425328, ...,  0.78816582,\n",
       "        -3.72614514,  0.86057789],\n",
       "       ...,\n",
       "       [-0.40141319, -0.49042688,  0.20753471, ...,  0.09391068,\n",
       "         0.34289385, -0.34758231],\n",
       "       [-0.40357903, -0.49042688, -1.16949207, ..., -0.7391955 ,\n",
       "         0.21589851, -0.75260628],\n",
       "       [ 0.30324229, -0.49042688,  0.96425328, ...,  0.78816582,\n",
       "         0.39790715, -1.35806871]])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.loadtxt(\"_training_boston_x_y_train.csv\",delimiter=\",\")\n",
    "# D1=pd.DataFrame(data.data,columns=data.feature_names) \n",
    "# IMPORTANT FEATURE TO CONVERT SCIKIT DATA INTO PANDAS DATA\n",
    "print(data.shape)\n",
    "print(data)\n",
    "x=data[:, :-1]\n",
    "y=data[:, -1]\n",
    "scaler=preprocessing.StandardScaler()\n",
    "scaler.fit(x)\n",
    "scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "b0cea17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y,learning_rate,m):\n",
    "    m_slope=np.zeros(len(X[0]))\n",
    "    M=len(X)\n",
    "    for i in range(len(X)):\n",
    "        x=X[i]\n",
    "        y=Y[i]\n",
    "        for j in range(len(x)):\n",
    "            m_slope[j]+=(-2/M)*(y-((m*x).sum()))*x[j]\n",
    "#             print(m_slope)\n",
    "    new_slope=m-(learning_rate*m_slope)\n",
    "    return new_slope\n",
    "# THE GRADIENT DESCENT FUNCTION PERFORMS GRADIENT DESCENT ON EACH DATA ROW BY MAKING AN ARRAY AND ALL THE SLOPES ARE SAVED INSIDE \n",
    "# THESE ARRAY WHICH IS USED AT LAST TO UPDATED BY LEARNING RATE AND RETURNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "315bc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(X_points,Y_points,learning_rate,num_iterations):\n",
    "    m=np.array([0 for i in range(len(X_points[0]))])\n",
    "#     this is a way to make numpy array and fill all the values in it to a specific value\n",
    "    for i in range(num_iterations):\n",
    "        m=gradient_descent(X_points,Y_points,learning_rate,m)\n",
    "#         print(m)\n",
    "        print(i,\": Cost:\",cost(X_points,Y_points,m))\n",
    "    return m\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "a0b56a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE COST FUNCTION TO CALCULATE THE COST TO SEE HOW ARE WE DOING IN TERMS OF OUR m\n",
    "\n",
    "def cost(X,Y,m):\n",
    "    M=len(X)\n",
    "    cost=0\n",
    "    for i in range(len(X)):\n",
    "        x=X[i]\n",
    "        y=Y[i]\n",
    "        cost+=(1/M)*((y-((m*x).sum()))**2)\n",
    "    \n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "d78975c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(x,y):\n",
    "   \n",
    "#     THE TYPE OF SCALING WE ARE USING HERE IS TO MAKE AN ARRAY WITH SQAURES OF THE DATASETS SO THAT WE ARE ABLE TO GET ALL THE\n",
    "#     NEAGTIVE VALUES AND ALSO SO THAT WE ARE ABLE TO PROPERLY GIVE WEIGHTAGE TO ALL PARAMETERS THAT IS THE VALUES ARE LESS THAN\n",
    "#     1 SO THE SCALING HAPPENS SUCH THAT VALUE GREATER IN VALUE THAN OTHER IS SCALED LESS BY SQAURING AND THE ONE HAVING LESS \n",
    "#     HAS ITS WEIGHTAGE INCREASED IN TERMS OF VALUE AND HENCE WEIGHTAGE\n",
    "   \n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    x=np.append(x, np.ones(len(x)).reshape(-1, 1), axis=1)\n",
    "    print(x.shape)\n",
    "    \n",
    "#     learning_rate=0.01\n",
    "#     num_iterations=500\n",
    "#     for above lr and iterations we get the last cost as: 17.124078149330174\n",
    "    learning_rate=0.1\n",
    "    num_iterations=500\n",
    "    m=gd(x,y,learning_rate,num_iterations)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "44c83bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40784991 -0.48772236 -1.2660231  ... -0.30309415  0.41057102\n",
      "  -1.09799011]\n",
      " [-0.40737368 -0.48772236  0.24705682 ...  0.1130321   0.29116915\n",
      "  -0.52047412]\n",
      " [ 0.1251786  -0.48772236  1.01599907 ...  0.80657583 -3.79579542\n",
      "   0.89107588]\n",
      " ...\n",
      " [-0.40831101 -0.48772236  0.24705682 ...  0.1130321   0.33206621\n",
      "  -0.33404299]\n",
      " [-0.41061997 -0.48772236 -1.15221381 ... -0.71922039  0.203235\n",
      "  -0.74475218]\n",
      " [ 0.34290895 -0.48772236  1.01599907 ...  0.80657583  0.38787479\n",
      "  -1.35871335]]\n",
      "(379, 13)\n",
      "(379, 14)\n",
      "0 : Cost: 374.24035597919686\n",
      "1 : Cost: 245.37909656079904\n",
      "2 : Cost: 165.10614192173668\n",
      "3 : Cost: 114.49508621191686\n",
      "4 : Cost: 82.43432664281796\n",
      "5 : Cost: 62.041704688310936\n",
      "6 : Cost: 49.0154746660482\n",
      "7 : Cost: 40.65519326019772\n",
      "8 : Cost: 35.25972835067592\n",
      "9 : Cost: 31.754121492629718\n",
      "10 : Cost: 29.457161634001743\n",
      "11 : Cost: 27.936007022144533\n",
      "12 : Cost: 26.914922412896374\n",
      "13 : Cost: 26.217802951980175\n",
      "14 : Cost: 25.731872822963105\n",
      "15 : Cost: 25.38469911771804\n",
      "16 : Cost: 25.129603525591076\n",
      "17 : Cost: 24.936384410518777\n",
      "18 : Cost: 24.785404792037365\n",
      "19 : Cost: 24.66381822190748\n",
      "20 : Cost: 24.56315514362143\n",
      "21 : Cost: 24.477776518190055\n",
      "22 : Cost: 24.403881200700226\n",
      "23 : Cost: 24.338867434896198\n",
      "24 : Cost: 24.280921148348455\n",
      "25 : Cost: 24.228749732407817\n",
      "26 : Cost: 24.18140930058519\n",
      "27 : Cost: 24.138192120101166\n",
      "28 : Cost: 24.09855285948923\n",
      "29 : Cost: 24.06205993819115\n",
      "30 : Cost: 24.028363158977218\n",
      "31 : Cost: 23.997171942483217\n",
      "32 : Cost: 23.968240497783352\n",
      "33 : Cost: 23.941357557710433\n",
      "34 : Cost: 23.916339140893513\n",
      "35 : Cost: 23.8930233395274\n",
      "36 : Cost: 23.871266478618274\n",
      "37 : Cost: 23.8509402167778\n",
      "38 : Cost: 23.83192930414061\n",
      "39 : Cost: 23.81412980765422\n",
      "40 : Cost: 23.797447675836793\n",
      "41 : Cost: 23.781797555694713\n",
      "42 : Cost: 23.767101801312183\n",
      "43 : Cost: 23.753289631473613\n",
      "44 : Cost: 23.740296405677086\n",
      "45 : Cost: 23.728062996050767\n",
      "46 : Cost: 23.716535238305664\n",
      "47 : Cost: 23.705663448792908\n",
      "48 : Cost: 23.695401997540312\n",
      "49 : Cost: 23.685708929185047\n",
      "50 : Cost: 23.676545625233352\n",
      "51 : Cost: 23.667876502228165\n",
      "52 : Cost: 23.659668741294816\n",
      "53 : Cost: 23.651892045237435\n",
      "54 : Cost: 23.644518419921997\n",
      "55 : Cost: 23.63752197714234\n",
      "56 : Cost: 23.630878756545357\n",
      "57 : Cost: 23.624566564510328\n",
      "58 : Cost: 23.61856482814464\n",
      "59 : Cost: 23.612854462787237\n",
      "60 : Cost: 23.607417751606427\n",
      "61 : Cost: 23.602238236046126\n",
      "62 : Cost: 23.597300616021258\n",
      "63 : Cost: 23.592590658888106\n",
      "64 : Cost: 23.58809511632606\n",
      "65 : Cost: 23.583801648361966\n",
      "66 : Cost: 23.579698753854302\n",
      "67 : Cost: 23.575775706825468\n",
      "68 : Cost: 23.57202249809743\n",
      "69 : Cost: 23.568429781741976\n",
      "70 : Cost: 23.564988825906966\n",
      "71 : Cost: 23.561691467625852\n",
      "72 : Cost: 23.558530071255525\n",
      "73 : Cost: 23.555497490223704\n",
      "74 : Cost: 23.552587031798264\n",
      "75 : Cost: 23.54979242461791\n",
      "76 : Cost: 23.547107788749056\n",
      "77 : Cost: 23.54452760805564\n",
      "78 : Cost: 23.542046704688318\n",
      "79 : Cost: 23.53966021551766\n",
      "80 : Cost: 23.537363570351094\n",
      "81 : Cost: 23.53515247178877\n",
      "82 : Cost: 23.53302287658537\n",
      "83 : Cost: 23.530970978397175\n",
      "84 : Cost: 23.528993191804343\n",
      "85 : Cost: 23.527086137506817\n",
      "86 : Cost: 23.52524662860241\n",
      "87 : Cost: 23.52347165786203\n",
      "88 : Cost: 23.521758385925132\n",
      "89 : Cost: 23.52010413034386\n",
      "90 : Cost: 23.51850635541158\n",
      "91 : Cost: 23.51696266271513\n",
      "92 : Cost: 23.515470782356683\n",
      "93 : Cost: 23.514028564794035\n",
      "94 : Cost: 23.51263397325362\n",
      "95 : Cost: 23.511285076672532\n",
      "96 : Cost: 23.50998004313109\n",
      "97 : Cost: 23.50871713373932\n",
      "98 : Cost: 23.507494696943347\n",
      "99 : Cost: 23.506311163222136\n",
      "100 : Cost: 23.50516504014468\n",
      "101 : Cost: 23.504054907762384\n",
      "102 : Cost: 23.50297941431194\n",
      "103 : Cost: 23.501937272206273\n",
      "104 : Cost: 23.50092725429293\n",
      "105 : Cost: 23.49994819036104\n",
      "106 : Cost: 23.498998963878357\n",
      "107 : Cost: 23.498078508942886\n",
      "108 : Cost: 23.497185807433222\n",
      "109 : Cost: 23.49631988634428\n",
      "110 : Cost: 23.495479815294544\n",
      "111 : Cost: 23.494664704193497\n",
      "112 : Cost: 23.49387370105789\n",
      "113 : Cost: 23.493105989966384\n",
      "114 : Cost: 23.49236078914302\n",
      "115 : Cost: 23.491637349160737\n",
      "116 : Cost: 23.490934951256712\n",
      "117 : Cost: 23.490252905751614\n",
      "118 : Cost: 23.48959055056614\n",
      "119 : Cost: 23.488947249827643\n",
      "120 : Cost: 23.488322392561372\n",
      "121 : Cost: 23.48771539146039\n",
      "122 : Cost: 23.487125681728436\n",
      "123 : Cost: 23.48655271999186\n",
      "124 : Cost: 23.485995983275057\n",
      "125 : Cost: 23.485454968035793\n",
      "126 : Cost: 23.484929189256274\n",
      "127 : Cost: 23.484418179586413\n",
      "128 : Cost: 23.483921488535696\n",
      "129 : Cost: 23.483438681710602\n",
      "130 : Cost: 23.482969340094932\n",
      "131 : Cost: 23.482513059369563\n",
      "132 : Cost: 23.482069449270057\n",
      "133 : Cost: 23.481638132978716\n",
      "134 : Cost: 23.481218746549956\n",
      "135 : Cost: 23.480810938365778\n",
      "136 : Cost: 23.480414368620643\n",
      "137 : Cost: 23.480028708832865\n",
      "138 : Cost: 23.47965364138145\n",
      "139 : Cost: 23.479288859067\n",
      "140 : Cost: 23.4789340646946\n",
      "141 : Cost: 23.478588970677727\n",
      "142 : Cost: 23.478253298662136\n",
      "143 : Cost: 23.477926779168083\n",
      "144 : Cost: 23.477609151249794\n",
      "145 : Cost: 23.477300162171982\n",
      "146 : Cost: 23.476999567101128\n",
      "147 : Cost: 23.476707128811633\n",
      "148 : Cost: 23.47642261740587\n",
      "149 : Cost: 23.476145810046713\n",
      "150 : Cost: 23.47587649070281\n",
      "151 : Cost: 23.475614449904928\n",
      "152 : Cost: 23.475359484513444\n",
      "153 : Cost: 23.47511139749602\n",
      "154 : Cost: 23.474869997715075\n",
      "155 : Cost: 23.47463509972426\n",
      "156 : Cost: 23.474406523573833\n",
      "157 : Cost: 23.47418409462431\n",
      "158 : Cost: 23.473967643367526\n",
      "159 : Cost: 23.47375700525561\n",
      "160 : Cost: 23.473552020536623\n",
      "161 : Cost: 23.473352534096904\n",
      "162 : Cost: 23.473158395309834\n",
      "163 : Cost: 23.472969457890468\n",
      "164 : Cost: 23.472785579756064\n",
      "165 : Cost: 23.47260662289165\n",
      "166 : Cost: 23.47243245322122\n",
      "167 : Cost: 23.47226294048346\n",
      "168 : Cost: 23.472097958112382\n",
      "169 : Cost: 23.471937383122157\n",
      "170 : Cost: 23.471781095996505\n",
      "171 : Cost: 23.47162898058194\n",
      "172 : Cost: 23.47148092398472\n",
      "173 : Cost: 23.47133681647201\n",
      "174 : Cost: 23.471196551375893\n",
      "175 : Cost: 23.471060025001282\n",
      "176 : Cost: 23.470927136536808\n",
      "177 : Cost: 23.470797787968767\n",
      "178 : Cost: 23.470671883998143\n",
      "179 : Cost: 23.47054933196037\n",
      "180 : Cost: 23.470430041747793\n",
      "181 : Cost: 23.470313925734832\n",
      "182 : Cost: 23.470200898705393\n",
      "183 : Cost: 23.470090877782965\n",
      "184 : Cost: 23.46998378236271\n",
      "185 : Cost: 23.46987953404615\n",
      "186 : Cost: 23.469778056577407\n",
      "187 : Cost: 23.469679275781953\n",
      "188 : Cost: 23.469583119507213\n",
      "189 : Cost: 23.469489517564792\n",
      "190 : Cost: 23.46939840167482\n",
      "191 : Cost: 23.46930970541187\n",
      "192 : Cost: 23.46922336415254\n",
      "193 : Cost: 23.469139315024876\n",
      "194 : Cost: 23.469057496858987\n",
      "195 : Cost: 23.468977850139318\n",
      "196 : Cost: 23.468900316958635\n",
      "197 : Cost: 23.468824840972967\n",
      "198 : Cost: 23.46875136735815\n",
      "199 : Cost: 23.468679842767575\n",
      "200 : Cost: 23.4686102152913\n",
      "201 : Cost: 23.468542434416293\n",
      "202 : Cost: 23.468476450987847\n",
      "203 : Cost: 23.46841221717211\n",
      "204 : Cost: 23.468349686419714\n",
      "205 : Cost: 23.468288813430664\n",
      "206 : Cost: 23.46822955411982\n",
      "207 : Cost: 23.468171865583805\n",
      "208 : Cost: 23.468115706068588\n",
      "209 : Cost: 23.468061034938202\n",
      "210 : Cost: 23.46800781264414\n",
      "211 : Cost: 23.46795600069574\n",
      "212 : Cost: 23.467905561631525\n",
      "213 : Cost: 23.467856458991097\n",
      "214 : Cost: 23.467808657288067\n",
      "215 : Cost: 23.467762121983544\n",
      "216 : Cost: 23.4677168194606\n",
      "217 : Cost: 23.467672716999225\n",
      "218 : Cost: 23.46762978275217\n",
      "219 : Cost: 23.46758798572125\n",
      "220 : Cost: 23.467547295734448\n",
      "221 : Cost: 23.467507683423843\n",
      "222 : Cost: 23.467469120203724\n",
      "223 : Cost: 23.46743157824959\n",
      "224 : Cost: 23.46739503047776\n",
      "225 : Cost: 23.467359450525272\n",
      "226 : Cost: 23.4673248127308\n",
      "227 : Cost: 23.467291092115545\n",
      "228 : Cost: 23.46725826436508\n",
      "229 : Cost: 23.46722630581155\n",
      "230 : Cost: 23.467195193416188\n",
      "231 : Cost: 23.467164904752686\n",
      "232 : Cost: 23.467135417990583\n",
      "233 : Cost: 23.467106711879545\n",
      "234 : Cost: 23.467078765733646\n",
      "235 : Cost: 23.46705155941638\n",
      "236 : Cost: 23.467025073326013\n",
      "237 : Cost: 23.46699928838121\n",
      "238 : Cost: 23.466974186007224\n",
      "239 : Cost: 23.466949748122353\n",
      "240 : Cost: 23.466925957124733\n",
      "241 : Cost: 23.466902795879598\n",
      "242 : Cost: 23.46688024770687\n",
      "243 : Cost: 23.46685829636901\n",
      "244 : Cost: 23.466836926059027\n",
      "245 : Cost: 23.46681612138942\n",
      "246 : Cost: 23.4667958673806\n",
      "247 : Cost: 23.466776149450403\n",
      "248 : Cost: 23.466756953403117\n",
      "249 : Cost: 23.46673826541953\n",
      "250 : Cost: 23.466720072046787\n",
      "251 : Cost: 23.46670236018861\n",
      "252 : Cost: 23.466685117095906\n",
      "253 : Cost: 23.466668330357432\n",
      "254 : Cost: 23.466651987890927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 : Cost: 23.466636077934353\n",
      "256 : Cost: 23.466620589037277\n",
      "257 : Cost: 23.466605510052695\n",
      "258 : Cost: 23.466590830128965\n",
      "259 : Cost: 23.46657653870196\n",
      "260 : Cost: 23.46656262548747\n",
      "261 : Cost: 23.46654908047358\n",
      "262 : Cost: 23.466535893913736\n",
      "263 : Cost: 23.46652305631949\n",
      "264 : Cost: 23.466510558453756\n",
      "265 : Cost: 23.466498391324016\n",
      "266 : Cost: 23.466486546176032\n",
      "267 : Cost: 23.46647501448732\n",
      "268 : Cost: 23.466463787961235\n",
      "269 : Cost: 23.466452858520615\n",
      "270 : Cost: 23.46644221830245\n",
      "271 : Cost: 23.46643185965172\n",
      "272 : Cost: 23.4664217751162\n",
      "273 : Cost: 23.46641195744102\n",
      "274 : Cost: 23.466402399563368\n",
      "275 : Cost: 23.46639309460741\n",
      "276 : Cost: 23.46638403587937\n",
      "277 : Cost: 23.466375216862716\n",
      "278 : Cost: 23.46636663121339\n",
      "279 : Cost: 23.466358272755336\n",
      "280 : Cost: 23.466350135475988\n",
      "281 : Cost: 23.46634221352191\n",
      "282 : Cost: 23.46633450119468\n",
      "283 : Cost: 23.46632699294669\n",
      "284 : Cost: 23.466319683377144\n",
      "285 : Cost: 23.466312567228332\n",
      "286 : Cost: 23.466305639381545\n",
      "287 : Cost: 23.466298894853725\n",
      "288 : Cost: 23.466292328793624\n",
      "289 : Cost: 23.466285936478407\n",
      "290 : Cost: 23.466279713310247\n",
      "291 : Cost: 23.466273654813058\n",
      "292 : Cost: 23.466267756629183\n",
      "293 : Cost: 23.466262014516285\n",
      "294 : Cost: 23.466256424344373\n",
      "295 : Cost: 23.466250982092692\n",
      "296 : Cost: 23.466245683846946\n",
      "297 : Cost: 23.466240525796433\n",
      "298 : Cost: 23.466235504231324\n",
      "299 : Cost: 23.46623061553986\n"
     ]
    }
   ],
   "source": [
    "m=run(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "72babb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO FINAL VALUE AFTER 600 ITERATIONS AND 0.1 LEARNING RATE IS 16.951229965909242"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037da7e",
   "metadata": {},
   "source": [
    "# PREDICTIONS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "3a73b134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "(127, 13)\n",
      "[[ 2.91816626 -0.48772236  1.01599907 ...  0.80657583 -1.59755122\n",
      "   1.04106182]\n",
      " [-0.40339151 -0.48772236  0.40609801 ... -1.13534664  0.44105193\n",
      "  -0.89473812]\n",
      " [-0.4131781  -0.48772236  0.11573841 ...  1.17646583  0.44105193\n",
      "  -0.50084979]\n",
      " ...\n",
      " [-0.41001449  2.08745172 -1.37837329 ... -0.0719129   0.39094481\n",
      "  -0.68167397]\n",
      " [-0.40317611 -0.48772236 -0.37597609 ...  1.13022958  0.34007019\n",
      "   0.20142086]\n",
      " [-0.13356344 -0.48772236  1.2319449  ... -1.73641788 -2.93893082\n",
      "   0.48877712]]\n",
      "[[ 2.91816626 -0.48772236  1.01599907 ... -1.59755122  1.04106182\n",
      "   1.        ]\n",
      " [-0.40339151 -0.48772236  0.40609801 ...  0.44105193 -0.89473812\n",
      "   1.        ]\n",
      " [-0.4131781  -0.48772236  0.11573841 ...  0.44105193 -0.50084979\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.41001449  2.08745172 -1.37837329 ...  0.39094481 -0.68167397\n",
      "   1.        ]\n",
      " [-0.40317611 -0.48772236 -0.37597609 ...  0.34007019  0.20142086\n",
      "   1.        ]\n",
      " [-0.13356344 -0.48772236  1.2319449  ... -2.93893082  0.48877712\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(m.shape)\n",
    "data=np.loadtxt(\"_test_boston_x_test.csv\",delimiter=\",\")\n",
    "print(data.shape)\n",
    "x=data[:,:]\n",
    "print(x)\n",
    "scaler.transform(x)\n",
    "x=np.append(x,np.ones(len(x)).reshape(-1,1),axis=1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "5915a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(testing):\n",
    "    scaler.transform(testing)\n",
    "    \n",
    "#     testing=np.append(testing, np.ones(len(testing)).reshape(-1, 1), axis=1)\n",
    "    \n",
    "    testing=np.append(testing, np.ones(len(testing)).reshape(-1, 1), axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    return testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "1369c9b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 13 features, but StandardScaler is expecting 26 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [530]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# print(sq.shape)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# testing=np.append(x, sq, axis=1)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# USED FOR DEBUGGING\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[43mscaling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [529]\u001b[0m, in \u001b[0;36mscaling\u001b[1;34m(testing)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscaling\u001b[39m(testing):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#     testing=np.append(testing, np.ones(len(testing)).reshape(-1, 1), axis=1)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     testing\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mappend(testing, np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(testing))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:973\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    970\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    972\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m--> 973\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 13 features, but StandardScaler is expecting 26 features as input."
     ]
    }
   ],
   "source": [
    "# print(sq.shape)\n",
    "# testing=np.append(x, sq, axis=1)\n",
    "\n",
    "# USED FOR DEBUGGING\n",
    "x=scaling(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "46497298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# y=np.zeros(len(x))\n",
    "# print(y.shape)\n",
    "# print(m)\n",
    "# print(m.shape)\n",
    "# USED FOR DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "77aee487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,m):\n",
    "    y=np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        y[i]=(m*x[i]).sum()\n",
    "    print(y)    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "add279ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.42989444 29.02039391 22.37354643 24.46703242 20.62175438  2.73145008\n",
      " 30.38110212 24.85603445 18.66257161 23.53976431 24.11358439 17.71638788\n",
      " 17.46398303 21.66356997 42.31859907 23.85979426 24.47528322 27.55265382\n",
      " 20.24532477 31.16515999 23.80379308 25.00538134 33.95493979 36.43002887\n",
      " 32.04938087 16.70445641 23.47622056 32.95854932 25.16710232 33.71101947\n",
      " 16.89127364 26.04023426 23.2739599  25.4751929  15.0088932  29.59188242\n",
      " 26.24833369 20.39050928 24.42398968  9.44836666  8.37393997 29.0090706\n",
      " 29.59695559 19.76416454 20.36709015  3.14047255 39.52275699 25.71759175\n",
      " 30.35514265 16.79149378 17.88628765 41.00335586 17.56938699 20.91121754\n",
      " 15.6030035  21.40397519 18.45407138 23.15688831 13.67742577 17.23112868\n",
      " 15.03166155 29.15154152 25.18664177 25.49703011 17.20547714 17.42690008\n",
      " 34.70150774 17.00983971 27.09514313 22.54014863 29.26989314 27.10732154\n",
      " 17.73547794  5.74313601 36.85962066 25.09462079 30.13860414 27.22994671\n",
      " 16.24953084 32.64595283 19.2690115  22.67245178 22.27110423  8.54144853\n",
      " 17.32718419 29.17866587 27.20308537  5.88063557 21.86287207 20.11062415\n",
      " 22.1751728  20.54108348 20.87232188 13.1795726  19.69969611 25.98809233\n",
      " 40.26312448 19.72513401 33.69482809 27.20622659 28.74019703 22.11100975\n",
      " 25.90682034 31.3156621  17.15224995 26.37322973 21.459334   36.75579126\n",
      " 22.0678539  16.70747292 27.60587464 -0.06551043 13.87545615 16.27968488\n",
      " 35.77025277 20.8729305  20.77949602 25.34578976 21.80117305 18.84682071\n",
      " 13.51950701 35.60573923 23.10133251 25.0032029  17.48988443 20.75564943\n",
      " 14.73184017]\n"
     ]
    }
   ],
   "source": [
    "y=predict(x,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "3e4cb8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(testing.shape)\n",
    "np.savetxt(X=y,fname=\"Predictions2.csv\",delimiter=\",\",fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c8717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
